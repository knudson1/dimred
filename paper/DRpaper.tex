\documentclass{article}

 \usepackage{url} 
\usepackage{amsthm,amsmath,amssymb,indentfirst,float}
\usepackage{verbatim}
\usepackage[sort,longnamesfirst]{natbib}
\newcommand{\pcite}[1]{\citeauthor{#1}'s \citeyearpar{#1}}
\newcommand{\ncite}[1]{\citeauthor{#1}, \citeyear{#1}}
\DeclareMathOperator{\logit}{logit}
    \DeclareMathOperator{\var}{Var}
   %  \DeclareMathOperator{\det}{det}
     \DeclareMathOperator{\diag}{diag}

\usepackage{geometry}
%\geometry{hmargin=1.025in,vmargin={1.25in,2.5in},nohead,footskip=0.5in} 
%\geometry{hmargin=1.025in,vmargin={1.25in,0.75in},nohead,footskip=0.5in} 
%\geometry{hmargin=2.5cm,vmargin={2.5cm,2.5cm},nohead,footskip=0.5in}

\renewcommand{\baselinestretch}{1.25}

\usepackage{amsbsy,amsmath,amsthm,amssymb,graphicx}

\setlength{\baselineskip}{0.3in} \setlength{\parskip}{.05in}


\newcommand{\cvgindist}{\overset{\text{d}}{\longrightarrow}}
\DeclareMathOperator{\PR}{Pr} 
\DeclareMathOperator{\cov}{Cov}


\newcommand{\sX}{{\mathsf X}}
\newcommand{\tQ}{\tilde Q}
\newcommand{\cU}{{\cal U}}
\newcommand{\cX}{{\cal X}}
\newcommand{\tbeta}{\tilde{\beta}}
\newcommand{\tlambda}{\tilde{\lambda}}
\newcommand{\txi}{\tilde{\xi}}




\title{Dimension Reduction of Random Effects for Generalized Linear Mixed Models}

\author{Zachary F, Clare Hillmer,  Adit Jain, Christina Knudson}

\begin{document}
\maketitle{}

\begin{abstract}
Welcome to the fun and beautiful world of latex. Here is a quick rundown but there's tons of excellent resources online.
\end{abstract}

\section{Equations and Code}
If you want to display math in the body of the text, you have to use dollar signs.
Let $y=(y_1, \ldots, y_n)^T$ be a vector of observed data. Let $u=(u_1,\ldots,u_q)'$ be a vector of unobserved random effects. Let $\beta$ be a vector of $p$ fixed effect parameters and let $\nu$ be a vector of $T$ variance components for the random effects. 

\begin{align}
l(\theta)=\log \int f_\theta(y|u) f_\theta(u) \; du
\end{align}
\textbf{The align environment is nice for typesetting equations. It'll give the equations numbers by default.}

Here's another equation. This one has fractions and exponents and sums.
\begin{align}\label{eq:myvalue}
v_\theta(u_k,y) = \dfrac{e^{b_k-a}}{ \sum_{k=1}^m e^{b_k-a}} 
\end{align}

And we can refer to it with \ref{eq:myvalue}. You can opt out of the equation numbers by using an asterisk. Check it out:

\begin{align*}
G &= \sum_{k=1}^m \nabla \log f_\theta (u_k,y) v_\theta(u_k,y)\\ \label{eq:gradient}
&= \sum_{k=1}^m \nabla \left[  \log f_\theta(y|u_k) + \log f_\theta (u_k)  \right] v_\theta(u_k,y)\\
&= \sum_{k=1}^m  \left[ \nabla \log f_\theta(y|u_k) + \nabla\log f_\theta (u_k)  \right] v_\theta(u_k,y)\\
&= \sum_{k=1}^m  \left[ \dfrac{\partial}{\partial \beta} \log f_\theta(y|u_k) \; \; \; \;  \dfrac{\partial}{\partial \nu} \log f_\theta(y|u_k) \right] v_\theta(u_k,y)+ \left[ \dfrac{\partial}{\partial \beta} \log f_\theta(u_k) \; \; \; \; \dfrac{\partial}{\partial \nu} \log f_\theta(u_k) \right] v_\theta(u_k,y)\\
\end{align*}
 You need to typeset it a couple times to make the reference numbers show up.  
You can also refer to a section in a similar way. Section \ref{sec:lists} contains more information on the family. Section \ref{sec:bullets}  shows you can also refer to subsections.


You'll notice this equation has multiple lines. To align the equal signs, we use  ampersand \&. 

\textbf{The verbatim environment is really nice for showing R code.}
\begin{verbatim}
glmm(y ~ x1+ x2, list(~0+school,~0+classroom),  family.glmm="binomial.glmm", 
data=schooldat,varcomps.names=c("school","classroom"),varcomps.equal=c(1,2),
debug=FALSE )
 \end{verbatim}



%$\Box$ Most of the time (but not all the time), the random effects formula should be ``0+...'' If the user does not specify ``0+'' then I want to give a warning something like ``Did you mean to start your random effects formula with 0+? Most models require this, so please check if you meant to include it.''


%%Families%%
\section{Lists and Such} \label{sec:lists}


\subsection{Bullets}\label{sec:bullets}
Here's how to make a list with bullets

\begin{itemize}

\item First item
\item Other item
\end{itemize}

You can get fancy with bullets if you want.

\subsection{Numbered List}

\begin{enumerate}

\item First item
\item Other item
\end{enumerate}

\section{Info on citations}
In the paper folder, I added brref.bib, which is the file that holds the bibliography info. Rather than  type the citation yourself, you can put your bib info in the brref file (using the setup that you see in there). You can see, for example, that I cite the R package aster by Charlie Geyer. In the brref file, the shortcut name is "aster-package" so when I want to cite this work in the paper, I can use one of the following options:
\begin{itemize}
\item The aster package \citep{aster-package} was created for life history models.
\item  \citet{aster-package} produced an R package that can analyze the radish data 
\end{itemize}

To make the citations and bibliography work, typeset the document a few times (pdfLaTeX), typeset with BibTeX, and then typeset with pdfLaTeX again. I don't remember the right number of times for each, so I usually do each a couple. It's easier to just hit typeset (or use the typeset keyboard shortcuts) than to memorize stuff like numbers. 

\section{Generalized Linear Mixed Models}
Generalized linear mixed models (GLMM) are versatile and can be used to answer a broad set of questions which can make them useful in many different fields of study.  To understand GLMM it is easiest to start with the well-known linear regression model.  This model makes assumptions about the response variable, such as the responses are independent, normal distributed, and have the same (equal) variance.  The linear models important for the study of GLMM are generalized linear models (GLM) and linear mixed models (LMM), both of which are extensions of GLMM. 

Throughout this paper, a dataset about mating salamanders will be used as an example.  This dataset includes two types of salamanders: rough butt (R) and white butt (W).  Female and male rough and white butts are involved in a series of mating trials in order to determine which type of mating combinations happen more frequently.  The different combinations (crosses) that were considered were: RW, RR, WR, and WW.
	
GLM encompasses the exponential family and linear models are a subset of GLM.  Examples of other models that are part of the exponential family include the binomial, poisson, and gamma models.  The link is a transformation of the response variables that makes general linear models more interpretable.  The most common types of links are the identity, logit and log link.  The salamander data follows a binomial model in that a pair of salamanders will either mate or not mate.  The binomial model requires a log link in order to transform the response variables into a continuous distribution.
	
LMM is a subset of GLMM that focuses specifically on linear models.  Mixed models are used to account for correlation(s) between explanatory variables.  One way to account for correlation is by adding random effects to our modeling function, which are variables assumed to be independent and identically distributed (i.i.d.).  In the salamander data there are two sets of random effects.  There are random effects for females with one variance and random effects for males with another variance.  The random effects in the salamander data come from an individual salamanderâ€™s willingness to mate.  A female salamander who mated with more males than the average female is given a positive random effect.  In contrast, a female salamander who mated less frequently than the average female is given a negative random effect. 
	
As explained above, the salamander data is a general linear model because it follows a binomial model that is transformed with the log link.  Furthermore, the salamander data is also a mixed model because it uses random effects for male and female salamander mating tendencies.  When these two aspects combine, a general linear model and a mixed model, the dataset can be analyzed with GLMM. 

\section{Monte Carlo Likelihood Approximation}
% Question to be answered in this section
% Why do we have an integral in the first place
% How does monte carlo methods help in estimating this integrals
% Why is this process a slow one 
To account for the random effects described in the previous section and get the likelihood function $L(\theta|y)$ (which will be used to calculate the coefficients) the random effects need to be integrated out of Eq. \ref{eq:pdf_uy} to obtain Eq.\ref{eq:likelihood} \\
\begin{equation}
f_\theta(u,y) = f_\beta(y|u)f_\nu(u)
\label{eq:pdf_uy}
\end{equation}
\begin{equation}
L(\theta{}|y) = \int f_\beta(y|u)f_\nu(u)du
\label{eq:likelihood}
\end{equation}


Since numerically integrating out the random effects for high dimensional data is not possible with the current computing power, some other technique to simulate these integrals needs to be employed. One other technique (which is used in the R package glmm) is to simulate these random effects using Monte Carlo Approximation .

We try to approximate the likelihood function of Eq \ref{eq:likelihood} by transforming it into a more suitable form of Eq. \ref{eq:importance} , where $\tilde{f}(u)$ is our importance sampling distribution. This is a distribution that we choose (in our case it turns out to be $N(0,1)$) in order to approximate the likelihood function. As can be shown Eq. \ref{eq:importance} is really just $E_{\tilde{f}}(\frac{f_\beta(y|u)f_\nu(u)}{\tilde{f}(u)})$. Now in order to run Monte Carlo simulations to estimate the likelihood, m values of \tilde{u} are chosen and the integral is calculated as a discrete sum of Eq. \ref{eq:estimatedsum}. Note that m is one of the parameter of the glmm package, and higher the value of m , the more closer is the estimated likelihood to the actual value. \\ 
Now to get a fairly good estimate we need the value of m set to be fairly high (of the order of $10^4 - 10^6$ ), which although is feasible for the computer but still takes up a a lot of time depending on the machine you are running it on. glmm package currently offers cluster support on multi core processors to tackle this challenge but that in itself has a limit of how much it can speed up things and so we try and explore ways in which we can reduce the dimensions of the random effects in the first place so that the approximation process takes less time. 
% Tell why does DR lead to reduction in time
% How are dimensions related to MCLE? or the integral?
% TODO
% Add bib ref to convergence of MCLA sum
%  is the importance sampling distribution written correctly?
% Add what theta beta and nu are.

\begin{equation}
L(\theta{}|y) = \int \frac{f_\beta(y|u)f_\nu(u)}{\tilde{f}(u)}\tilde{f}(u)du
% What would come as subscript of f(\tilde{u}) ?
\label{eq:importance}
\end{equation}
\begin{equation}
 \frac{1}{m} \sum\limits_{k=1}^m \frac{f_\beta(y|u_k)f_\nu(u_k)}{\tilde{f}(u_k)} =   \frac{1}{m} \sum\limits_{k=1}^m \frac{f_\theta(y,u_k)}{\tilde{f}(u_k)} 
\label{eq:estimatedsum}
\end{equation}




\section{Dimension Reduction Methods}
Three different methods were used to explore the effects of dimension reduction on runtime and response variables.  The methods used for this research were rounding, quantile grouping and lasso.  Each method will be described in detail in the following subsections.

\subsection{Rounding}
	Rounding is mathematically the most straight-forward method.  Random effects are rounded to a specific decimal place.  The rounded random effects that are the same are then collapsed into one random effect.  The two random effects for the salamander data were rounded to the nearest tenth and hundredth.  This reduced the dimensions of the random effects from 60 to 25 for both males and females when rounded to the tenth.  When rounded to the hundredths, the dimensions of the random effects were 56 for females and 58 for males.  

\subsection{Quantile Grouping}
	Since it is assumed that random effects follow a normal distribution, random effects can be collapsed by quantile.  A function was created that took in random effects, the standard deviation of the random effects and the number of quantiles wanted.  It then collapsed the dimensions of the random effects by the number of quantiles specified. 

\bibliographystyle{apalike}
\bibliography{brref}

\end{document}
